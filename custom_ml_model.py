# -*- coding: utf-8 -*-
"""Custom ML Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AWJ62ohluuri9tXzo5sqbeccrsJ0p-oV

# **Creating a custom Machine Learning model and training with your own dataset.**

Step 1: Gather images that you need to classify and create a labelled dataset.

This means creating a folder structure in which each subfolder represents a different class and contains images that belong to that class. For example, you might have a dataset with the following folder structure:

dataset/
    class_1/
        image_1.jpg
        image_2.jpg
        ...
    class_2/
        image_1.jpg
        image_2.jpg
        ...
    ...

Step 2: Preprocess the dataset
"""

from keras.preprocessing.image import ImageDataGenerator

# Resize all images to a uniform size
img_width, img_height = 128, 128

# Create a generator that will rescale the images and convert them to a uniform format
datagen = ImageDataGenerator(rescale=1./255)

# Create a generator that will read images from the dataset and generate batches of augmented data
train_generator = datagen.flow_from_directory(
    'dataset/train',  # this is the directory where the training images are stored
    target_size=(img_width, img_height),  # resize all images to this size
    batch_size=32,
    class_mode='categorical')  # the labels are categorical

# Repeat the same process for the validation and test sets
validation_generator = datagen.flow_from_directory(
    'dataset/validation',
    target_size=(img_width, img_height),
    batch_size=32,
    class_mode='categorical')

test_generator = datagen.flow_from_directory(
    'dataset/test',
    target_size=(img_width, img_height),
    batch_size=32,
    class_mode='categorical')

"""Step 3 & 4: Create a machine learning model defining the model architecture"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Define the model as a sequential model
model = Sequential()

# Add a convolutional layer with 32 filters of size 3x3
model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'))

# Add a max pooling layer
model.add(MaxPooling2D(pool_size=(2, 2)))

# Add another convolutional layer with 64 filters of size 3x3
model.add(Conv2D(64, (3, 3), activation='relu'))

# Add another max pooling layer
model.add(MaxPooling2D(pool_size=(2, 2)))

# Flatten the output from the convolutional layers
model.add(Flatten())

# Add a fully connected layer with 128 neurons
model.add(Dense(128, activation='relu'))

# Add a final layer with the same number of neurons as the number of classes
model.add(Dense(train_generator.num_classes, activation='softmax'))

"""Step 5: Compile the model"""

model.compile(optimizer='adam',  # a good optimizer for most tasks
              loss='categorical_crossentropy',  # a common choice for classification tasks
              metrics=['accuracy'])  # track the accuracy of the model

"""Step 6: Train the model"""

model.fit_generator(
    train_generator,  # the generator that yields batches of training data
    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # number of steps to run the generator for
    epochs=10,  # number of epochs to train for
    validation_data=validation_generator,  # the generator that yields batches of validation data
    validation_steps=validation_generator.samples // validation_generator.batch_size)  # number of steps to run the generator for

"""Step 7: Evaluate the model on the validation set"""

val_loss, val_acc = model.evaluate_generator(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)
print("Validation loss:", val_loss)
print("Validation accuracy:", val_acc)

"""Step 8: Fine-tune the model

This step may involve adjusting the model architecture, changing the learning rate, or adding regularization
For example, you might try adding more layers, increasing the number of filters in the convolutional layers, or adding dropout

Step 9: Test the model on the test set
"""

test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // test_generator.batch_size)
print("Test loss:", test_loss)
print("Test accuracy:", test_acc)